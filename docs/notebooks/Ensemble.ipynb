{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we'll show how to perform a very simple ensemble analysis to infer the statistical properties of the spots on a group of stars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = \"retina\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Disable annoying font warnings\n",
    "matplotlib.font_manager._log.setLevel(50)\n",
    "\n",
    "# Disable theano deprecation warnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=matplotlib.MatplotlibDeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"theano\")\n",
    "\n",
    "# Style\n",
    "plt.style.use(\"default\")\n",
    "plt.rcParams[\"savefig.dpi\"] = 100\n",
    "plt.rcParams[\"figure.dpi\"] = 100\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 4)\n",
    "plt.rcParams[\"font.size\"] = 14\n",
    "plt.rcParams[\"text.usetex\"] = False\n",
    "plt.rcParams[\"font.family\"] = \"sans-serif\"\n",
    "plt.rcParams[\"font.sans-serif\"] = [\"Liberation Sans\"]\n",
    "plt.rcParams[\"font.cursive\"] = [\"Liberation Sans\"]\n",
    "try:\n",
    "    plt.rcParams[\"mathtext.fallback\"] = \"cm\"\n",
    "except KeyError:\n",
    "    plt.rcParams[\"mathtext.fallback_to_cm\"] = True\n",
    "plt.rcParams[\"mathtext.fallback_to_cm\"] = True\n",
    "\n",
    "# Short arrays when printing\n",
    "np.set_printoptions(threshold=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "del matplotlib\n",
    "del plt\n",
    "del warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from corner import corner as _corner\n",
    "\n",
    "\n",
    "def corner(*args, **kwargs):\n",
    "    \"\"\"\n",
    "    Override `corner.corner` by making some appearance tweaks.\n",
    "\n",
    "    \"\"\"\n",
    "    # Get the usual corner plot\n",
    "    figure = _corner(*args, **kwargs)\n",
    "\n",
    "    # Get the axes\n",
    "    ndim = int(np.sqrt(len(figure.axes)))\n",
    "    axes = np.array(figure.axes).reshape((ndim, ndim))\n",
    "\n",
    "    # Smaller tick labels\n",
    "    for ax in axes[1:, 0]:\n",
    "        for tick in ax.yaxis.get_major_ticks():\n",
    "            tick.label.set_fontsize(10)\n",
    "        formatter = matplotlib.ticker.ScalarFormatter(useOffset=False)\n",
    "        ax.yaxis.set_major_formatter(formatter)\n",
    "        ax.set_ylabel(ax.get_ylabel(), fontsize=kwargs.get(\"corner_label_size\", 16))\n",
    "    for ax in axes[-1, :]:\n",
    "        for tick in ax.xaxis.get_major_ticks():\n",
    "            tick.label.set_fontsize(10)\n",
    "        formatter = matplotlib.ticker.ScalarFormatter(useOffset=False)\n",
    "        ax.xaxis.set_major_formatter(formatter)\n",
    "        ax.set_xlabel(ax.get_xlabel(), fontsize=kwargs.get(\"corner_label_size\", 16))\n",
    "\n",
    "    # Pad the axes to always include the truths\n",
    "    truths = kwargs.get(\"truths\", None)\n",
    "    if truths is not None:\n",
    "        for row in range(1, ndim):\n",
    "            for col in range(row):\n",
    "                lo, hi = np.array(axes[row, col].get_xlim())\n",
    "                if truths[col] < lo:\n",
    "                    lo = truths[col] - 0.1 * (hi - truths[col])\n",
    "                    axes[row, col].set_xlim(lo, hi)\n",
    "                    axes[col, col].set_xlim(lo, hi)\n",
    "                elif truths[col] > hi:\n",
    "                    hi = truths[col] - 0.1 * (hi - truths[col])\n",
    "                    axes[row, col].set_xlim(lo, hi)\n",
    "                    axes[col, col].set_xlim(lo, hi)\n",
    "\n",
    "                lo, hi = np.array(axes[row, col].get_ylim())\n",
    "                if truths[row] < lo:\n",
    "                    lo = truths[row] - 0.1 * (hi - truths[row])\n",
    "                    axes[row, col].set_ylim(lo, hi)\n",
    "                    axes[row, row].set_xlim(lo, hi)\n",
    "                elif truths[row] > hi:\n",
    "                    hi = truths[row] - 0.1 * (hi - truths[row])\n",
    "                    axes[row, col].set_ylim(lo, hi)\n",
    "                    axes[row, row].set_xlim(lo, hi)\n",
    "\n",
    "    return figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will generate a synthetic ensemble of light curves of stars with \"similar\" spot properties. Let's define some true values for the spot properties of the ensemble:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truths = {\"r\": 15, \"mu\": 30, \"sigma\": 5, \"c\": 0.05, \"n\": 20}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "from starry_process.defaults import defaults\n",
    "\n",
    "display(\n",
    "    Markdown(\n",
    "        \"\"\"\n",
    "| parameter | description | true value\n",
    "| - | :- | :-:\n",
    "| `r` | mean radius in degrees | `{r}`\n",
    "| `mu` | latitude distribution mode in degrees | `{mu}`\n",
    "| `sigma` | latitude distribution standard deviation in degrees | `{sigma}`\n",
    "| `c` | fractional spot contrast | `{c}`\n",
    "| `n` | number of spots | `{n}`\n",
    "\"\"\".format(\n",
    "            **truths\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's generate 500 light curves from stars at random inclinations with spots drawn from the distributions above.\n",
    "We'll do this by adding discrete circular spots to each star via the `starry_process.calibrate.generate`\n",
    "function.\n",
    "Note that in order to mimic real observations, we'll normalize each light curve to its mean value and subtract unity to get the \"relative\" flux.\n",
    "For simplicity, we'll give all of the light curves the same period and photometric uncertainty."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. note::\n",
    "\n",
    "    The ``starry_process.calibrate`` module is used internally to verify the calibration of the Gaussian process, so it's not very well documented. You can check out the list of valid keyword arguments to the ``generate`` function `here <https://github.com/rodluger/starry_process/blob/ba90c7e7ff9a89939ad35ad331404f050027805d/starry_process/calibrate/defaults.json>`_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from starry_process import calibrate\n",
    "\n",
    "data = calibrate.generate(\n",
    "    generate=dict(\n",
    "        normalized=True,\n",
    "        nlc=500,\n",
    "        period=1.0,\n",
    "        ferr=1e-3,\n",
    "        nspots=dict(mu=truths[\"n\"]),\n",
    "        radius=dict(mu=truths[\"r\"]),\n",
    "        latitude=dict(mu=truths[\"mu\"], sigma=truths[\"sigma\"]),\n",
    "        contrast=dict(mu=truths[\"c\"]),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable `data` is a dictionary containing the light curves, the stellar maps (expressed as vectors of spherical harmonic coefficients `y`), plus some metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = data[\"t\"]\n",
    "flux = data[\"flux\"]\n",
    "ferr = data[\"ferr\"]\n",
    "y = data[\"y\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize some of the light curves, all on the same scale:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(3, 5)\n",
    "for j, axis in enumerate(ax.flatten()):\n",
    "    axis.plot(t, flux[j] * 1000)\n",
    "    axis.set_ylim(-50, 50)\n",
    "    axis.set_xticks([0, 1, 2, 3, 4])\n",
    "    if j != 10:\n",
    "        axis.set_xticklabels([])\n",
    "        axis.set_yticklabels([])\n",
    "    else:\n",
    "        axis.set_xlabel(\"rotations\")\n",
    "        axis.set_ylabel(\"flux [ppt]\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next section, we'll assume we observe only these 500 light curves. We do not know the inclinations of any of the stars or anything about their spot properties: only that all the stars have statistically similar spot distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set up a simple probabilistic model using `pymc3` and solve for the five quantities above: the spot radius, the mode and standard deviation of the spot latitude, the spot contrast, and the number of spots. We'll place uniform priors on everything except for the latitude mode `mu`, on which we'll place an isotropic prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from starry_process import StarryProcess\n",
    "import pymc3 as pm\n",
    "import theano.tensor as tt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "with pm.Model() as model:\n",
    "\n",
    "    # For use later\n",
    "    varnames = [\"r\", \"mu\", \"sigma\", \"c\", \"n\"]\n",
    "\n",
    "    # Spot latitude params. Isotropic prior on the mode\n",
    "    # and uniform prior on the standard deviation\n",
    "    u = pm.Uniform(\"u\", 0, 1)\n",
    "    mu = 90 - tt.arccos(u) * 180 / np.pi\n",
    "    pm.Deterministic(\"mu\", mu)\n",
    "    sigma = pm.Uniform(\"sigma\", 1.0, 20.0)\n",
    "\n",
    "    # Spot radius (uniform prior)\n",
    "    r = pm.Uniform(\"r\", 10.0, 30.0)\n",
    "\n",
    "    # Spot contrast & number of spots (uniform prior)\n",
    "    c = pm.Uniform(\"c\", 0.0, 0.5, testval=0.1)\n",
    "    n = pm.Uniform(\"n\", 1.0, 30.0, testval=5)\n",
    "\n",
    "    # Instantiate the GP\n",
    "    sp = StarryProcess(r=r, mu=mu, sigma=sigma, c=c, n=n)\n",
    "\n",
    "    # Compute the log likelihood\n",
    "    lnlike = sp.log_likelihood(t, flux, ferr ** 2, p=1.0)\n",
    "    pm.Potential(\"lnlike\", lnlike)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. note::\n",
    "\n",
    "   Note that we explicitly provide a small ``testval`` for both the spot contrast and the number of spots. Otherwise, the initial value assumed in the optimization for both those quantities is the midpoint of the bounds (`c = 0.5` and `n = 25.5`). That corresponds to a *lot* of *very dark* spots, which results in very high variance in the flux -- too high, in fact, for the normalized Gaussian process to model! We discusss this in more detail in the paper. To avoid initializing the sampler in a bad region of parameter space, we provide a starting point that is guaranteed to lead to a finite log likelihood value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we can do is to optimize the log probability function to get the MAP (maximum a posteriori) solution -- that will be a good estimate of the true spot properties since there are so many light curves in our ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from starry_process import MCMCInterface\n",
    "\n",
    "with model:\n",
    "    mci = MCMCInterface()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mci.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwalkers = 30\n",
    "p0 = mci.get_initial_state(nwalkers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emcee\n",
    "\n",
    "ndim = p0.shape[1]\n",
    "sampler = emcee.EnsembleSampler(nwalkers, ndim, mci.logp)\n",
    "np.random.seed(0)\n",
    "_ = sampler.run_mcmc(p0, 1000, progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the walkers\n",
    "fig, ax = plt.subplots(ndim, figsize=(8, 8), sharex=True)\n",
    "for k in range(sampler.chain.shape[0]):\n",
    "    for j in range(sampler.chain.shape[2]):\n",
    "        ax[j].plot(sampler.chain[k, :, j], \"C0-\", lw=1, alpha=0.3)\n",
    "ax[-1].set_xlabel(\"iteration\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burnin = 200\n",
    "samples = sampler.chain[:, burnin:, :].reshape(-1, ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varnames = [\"r\", \"mu\", \"sigma\", \"c\", \"n\"]\n",
    "samples = mci.transform(samples, varnames=varnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from corner import corner\n",
    "\n",
    "# View the posteriors\n",
    "corner(\n",
    "    samples,\n",
    "    labels=varnames,\n",
    "    truths=[truths[name] for name in varnames],\n",
    "    range=((10, 30), (0, 90), (1, 20), (0, 0.5), (1, 30)),\n",
    "    truth_color=\"C1\",\n",
    "    bins=100,\n",
    "    smooth=2,\n",
    "    smooth1d=2,\n",
    ");"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
